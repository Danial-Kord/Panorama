{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panorama"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT\n",
    "First we load 2 images and they we use built-in OpenCV SIFT implementation to detect our feature points.\n",
    "Then we use `BFMatcher` to match points. I used KNN matcher in this project. And then we filter them to have better matching. Finally we use `drawMatches` function to draw matches and save result in `2_matches.png`\n",
    "\n",
    "<img src=\"./2_matches.png\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the two images\n",
    "img1 = cv2.imread(\"2.png\")\n",
    "img2 = cv2.imread(\"1.png\")\n",
    "\n",
    "# Initialize SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# Compute the keypoints and descriptors for both images\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "# Use BFMatcher to find the best matches\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2, k=2)\n",
    "\n",
    "# Filter the matches based on their distance\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "# Draw the matches using drawMatches function\n",
    "img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# save SIFT\n",
    "cv2.imwrite(\"2_matches.png\", img3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography and RANSAC\n",
    "\n",
    "I implemented the RANSAC algorithm to find the best inliers to have a better Homography matrix. At each iteration we run thr RANSAC algorithm to randomly select points(there are maximum `num_iterations` iterations). Then at each iteration regarding the randomly selected pair points (`random_src_pts` and `random_dst_pts`) we find the homography matrix based on these points using `findHomography` function. Then as we now have our homography matrix ready, we find all destination points based on source points(`src_pts`), we call it `dst_pts_transformed`. Now we have new destination points and we had our original destination points, so we find the difference between the points and if we only select pair of points which have the difference from the original points if they are less than a threshold. At last we save this inliers if the length of our last set of inliers is less than our new founded one, otherwise we relize that these selection of points are not good matches becasue they could not desribe all match points so we delete them and run the algorithm again on the remaining set. Below is the function implemented. It receives `src_pts, dst_pts, num_iterations, threshold` and give us the `best_homography` and `best_inliers` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RANSAC(src_pts, dst_pts, num_iterations, threshold):\n",
    "    best_homography = None\n",
    "    best_inliers = []\n",
    "    for i in range(num_iterations):\n",
    "        # Randomly select 4 pairs of matched points\n",
    "        random_indices = np.random.randint(0, len(src_pts), 8)\n",
    "        random_src_pts = src_pts[random_indices]\n",
    "        random_dst_pts = dst_pts[random_indices]\n",
    "\n",
    "        # Estimate the homography matrix using the random points\n",
    "        homography_matrix, _ = cv2.findHomography(random_src_pts, random_dst_pts)\n",
    "\n",
    "\n",
    "        # Calculate the distances between the transformed source points and the destination points\n",
    "        dst_pts_transformed = cv2.perspectiveTransform(src_pts, homography_matrix)\n",
    "        difference = dst_pts - dst_pts_transformed\n",
    "\n",
    "        distances = np.linalg.norm(difference, axis=1)\n",
    "\n",
    "        # Select the inliers based on the threshold\n",
    "        inliers = np.where(distances < threshold)[0]\n",
    "        # print(inliers)\n",
    "        # Update the best homography and inliers if the current set is better\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_homography = homography_matrix\n",
    "            best_inliers = inliers\n",
    "        else:\n",
    "            np.delete(src_pts, random_indices)\n",
    "            np.delete(dst_pts, random_indices)\n",
    "\n",
    "    return best_homography, best_inliers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we call RANSAC with given src and dst points and after receivign homography matrix and set of inliers, we save the image for both inliers and outliers sets\n",
    "- inliers\n",
    "<br>\n",
    "<img src=\"./2_inliers.png\" width=\"900\">\n",
    "- outliers\n",
    "<br>\n",
    "<img src=\"./2_outliers.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the matched keypoints to coordinates\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "# Homography and RANSAC\n",
    "homography_matrix, inliers = RANSAC(src_pts, dst_pts, 100, 2500)\n",
    "\n",
    "# save Inliers\n",
    "inlier_matches = [good[i] for i in inliers]\n",
    "img_inliers = cv2.drawMatches(img1, kp1, img2, kp2, inlier_matches, None, flags = cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor = (0,255,0))\n",
    "cv2.imwrite(\"2_inliers.png\", img_inliers)\n",
    "\n",
    "# save Outliers\n",
    "outlier_matches = [good[i] for i in range(len(good)) if i not in inliers]\n",
    "img_outliers = cv2.drawMatches(img1, kp1, img2, kp2, outlier_matches, None, flags = cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor = (255,0,0))\n",
    "cv2.imwrite(\"2_outliers.png\", img_outliers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Panorama image\n",
    "Now we use `wrapPerspective` function for defining combination of two images with respect to homography matrix.\n",
    "Now we copy the results to the final destination image and save it.\n",
    "I had problem with creating panorama image, even with using predefined RANSAC instead of my implementation, it did not work properly.\n",
    "\n",
    "<img src=\"panorama.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dst = cv2.warpPerspective(img1, homography_matrix, (img1.shape[1]*2 + img2.shape[1], img1.shape[0]*2), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "dst[0:img2.shape[0], 0:img2.shape[1]] = img2\n",
    "# Save the result\n",
    "cv2.imwrite(\"panorama.png\", dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete code is available at `Panorama.py` file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
